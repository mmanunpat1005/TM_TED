---
title: "Topic modeling"
author: "Ting Yang"
date: "05/12/2022"
output: html_document
---

```{r,include=FALSE}
source(here::here("scripts/setup.R"))
```

# 6. Topic modeling  

Topic modeling is a method for discovering the latent themes or topics that exist within a collection of documents. Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) are two popular techniques for topic modeling. 

## 6.1 LSA

### 6.1.1 LSA on TF
First, we build the LSA object with 4 dimensions. Latent Semantic Analysis(LSA) decomposes the DTM (TED.dfm) into 3 matrices ($M = U\Sigma V^{t}$), centred around 4 topics. We examine the 3 matrices: **U:Doc-topic sim**, **Î£:Topic strength** and **V:Terms-topic sim**. 

The **Doc-topic sim** table below shows the link between each text and each category. For example, text1 is most relevant to dimension 2.

```{r, echo=TRUE, warning=FALSE}
TED.lsa <- textmodel_lsa(x = TED.dfm,nd = 4)
kable(TED.lsa$docs, 
      col.names = c("dimension1","dimension2","dimension3","dimension4"),
      caption = "Doc-topic sim.(LSA on TF)") %>%
   kable_paper() %>%
   kableExtra::scroll_box(width = "100%", height = "200px")
```

<br>
The **Topic strength** table below represents the strength of each dimension. 
```{r , echo=TRUE, warning=FALSE}
CN <- c("dimension1","dimension2","dimension3","dimension4")
Topic_Strength <- data.frame(CN,TED.lsa$sk)
colnames(Topic_Strength) <- c("Dimension", "Topic strength")

head(Topic_Strength) %>% flextable() %>% add_header_lines("Topic strength by dimension") %>% autofit()

```
<br>
The **Terms-topic sim.** table below shows the link between each term and each dimension. For example, the term "artificial" is most relevant to dimension 2.
```{r, echo=TRUE, warning=FALSE}
kable(head(TED.lsa$features,10), 
      col.names = c("dimension1","dimension2","dimension3","dimension4"),
      caption = "Terms-topic sim.(LSA on TF)") %>%
   kable_paper() %>%
   kableExtra::scroll_box(width = "100%", height = "200px")
```
<br>
The first dimension of LSA is often correlated with the document length and the frequency of the term. This phenomenon can be visualized through the construction of a scatter plot between the document length and the first dimension of the latent semantic space. 

```{r, echo=TRUE, warning=FALSE ,fig.height = 3}
doc.freq <- ntoken(TED.tk) # row-sum of the DTM.
data.frame(doc.freq,
           dim1 = TED.lsa$docs[, 1]) %>% 
  ggplot(aes(doc.freq, dim1)) + 
  geom_point() + 
  geom_smooth(method="lm",
              formula = 'y ~ x') +
  labs(
    title="The relationship between the number of tokens in documents and the values in LSA dimension 1",
    x="Number of tokens",
    y="LSA dim. 1"
  )
```

We then examine the top words in dimension 2, 3, and 4. For each dimension, we look at the five terms with the largest values and the five ones with the lowest values (i.e., largest negative value).

According to the table below, Dimension 2 is associated positively with "ai", "human", "robot", "machine" ,"datum", and negatively associated with "feel", "climate", "life", "love", "people".
```{r, echo=TRUE, warning=FALSE}
n.terms <- 5
## For Dimension 2
w.order <- sort(TED.lsa$features[, 2],decreasing = TRUE)
w.top.d2 <- c(w.order[1:n.terms],rev(rev(w.order)[1:n.terms]))
## For Dimension 3
w.order <- sort(TED.lsa$features[, 3], decreasing = TRUE)
w.top.d3 <- c(w.order[1:n.terms], rev(rev(w.order)[1:n.terms]))
## For Dimension 4
w.order <- sort(TED.lsa$features[,4], decreasing = TRUE)
w.top.d4 <- c(w.order[1:n.terms], rev(rev(w.order)[1:n.terms]))

w.top.d2 <- t(w.top.d2)
kable(w.top.d2, 
      caption = "Top 5 and bottom 5 of Dimension2 (LSA on TF)") %>%
   kable_paper()

```
<br>
The below table shows that Dimension 3 is associated positively with "people", "love", "robot", "feel" ,"life", and negatively associated with "forest", "year", "energy", "carbon", "climate".

```{r, echo=TRUE, warning=FALSE}

w.top.d3 <- t(w.top.d3)
kable(w.top.d3, 
      caption = "Top 5 and bottom 5 of Dimension3 (LSA on TF)") %>%
   kable_paper()

```
<br>
The below table shows that Dimension 4 is associated positively with "robot", "thing", "rule", "move" ,"start", and negatively associated with "datum", "human", "love", "people", "ai".

```{r, echo=TRUE, warning=FALSE}

w.top.d4 <- t(w.top.d4)
kable(w.top.d4, 
      caption = "Top 5 and bottom 5 of Dimension4 (LSA on TF)") %>%
   kable_paper() 

```
<br>
In order to confirm the relation between LSA and categories of text, we combine the LSA result with the categories of text and represent every text on these two following plots. 
```{r, echo=TRUE, warning=FALSE, fig.height = 4}

TED.lsa.source <- TED_full %>% 
  select(2) %>% cbind(as.data.frame(TED.lsa$docs))

LSA_p1 <- ggplot(data=TED.lsa.source,mapping = aes(
  x=V2,
  y=V3,
  color=cate))+
  geom_point()+
  labs(x = "dimension2",
       y = "dimension3",
       title = "Distribution of texts in different categories",
       subtitle = "LSA(TF) dimension 2 and 3")+
  scale_colour_discrete(
    name="Category",
    breaks=c("1","2","3"),
    labels=c("AI","Climate change","Relationships")
  )+
  theme(plot.title = element_text(size = 12))

LSA_P2 <- ggplot(data=TED.lsa.source,mapping = aes(
  x=V3,
  y=V4,
  color=cate))+
  geom_point()+
  labs(x = "dimension3",
       y = "dimension4",
       title = "Distribution of texts in different categories",
       subtitle = "LSA(TF):dimension 3 and 4")+
  scale_colour_discrete(
    name="Category",
    breaks=c("1","2","3"),
    labels=c("AI","Climate change","Relationships")
  )+
  theme(plot.title = element_text(size = 12))

(LSA_p1+LSA_P2)+
  plot_layout(guides = "collect") & theme(legend.position = 'bottom')
```

From the left hand side plot, x-axis represents dimension 2 and y-axis represents dimension3. According to this plot, the "Climate change" category is negatively associated with dimension3 while, the "Relationships" category is positively associated with dimension3. Additionally, the "AI" category is positively associated with dimension2.

For the right hand side plot, x-axis represents dimension 3 and y-axis represents dimension4. According to this plot, the "Climate change" and the "Relationships" categories seem to be not associated with dimension4. However, the "AI" category is associated with dimension 4, although there is some variability in the direction of this association.

### 6.1.2 LSA on TF-IDF
We also perform the LSA with the TF-IDF matrix to examine whether the weighted frequency can improve the interpretation.

Regarding the Doc-topic sim. table, which demonstrates the relationship between each text and each dimension. For example, text3 is most relevant to dimension 3.
```{r, echo=TRUE, warning=FALSE}
TED.lsa2 <- textmodel_lsa(TED.tfidf, nd = 4) 

kable(TED.lsa2$docs, 
      col.names = c("dimension1","dimension2","dimension3","dimension4"),
      caption = "Doc-topic sim.(LSA on TF-IDF)") %>%
   kable_paper() %>%
   kableExtra::scroll_box(width = "100%", height = "200px")
```
<br>
This Topic strength table represents the strength of each dimension. For example, dimension 4 has the smallest strength.
```{r, echo=TRUE, warning=FALSE}
Topic_Strength2 <- data.frame(CN,TED.lsa2$sk)
colnames(Topic_Strength2) <- c("Dimension", "Topic strength")

head(Topic_Strength2) %>% flextable() %>% add_header_lines("Topic strength by dimension") %>% autofit()
  
```
<br>
This Terms-topic sim. table shows the link between each term and each dimension. For example, the terms "artificial" and "intelligence" are both most relevant to dimension 3.
```{r, echo=TRUE, warning=FALSE}
kable(head(TED.lsa2$features,10), 
      col.names = c("dimension1","dimension2","dimension3","dimension4"),
      caption = "Terms-topic sim.(LSA on TF-IDF)") %>%
   kable_paper() %>%
   kableExtra::scroll_box(width = "100%", height = "200px")
```
<br>

We also would like to see the top words for dimension2, 3, and 4 of LSA on TF-IDF.
```{r, echo=TRUE, warning=FALSE}
## For Dimension 2
w2.order <- sort(TED.lsa2$features[, 2],decreasing = TRUE)
w2.top.d2 <- c(w2.order[1:n.terms],rev(rev(w2.order)[1:n.terms]))
## For Dimension 3
w2.order <- sort(TED.lsa2$features[, 3], decreasing = TRUE)
w2.top.d3 <- c(w2.order[1:n.terms], rev(rev(w2.order)[1:n.terms]))
## For Dimension 4
w2.order <- sort(TED.lsa2$features[, 4], decreasing = TRUE)
w2.top.d4 <- c(w2.order[1:n.terms], rev(rev(w2.order)[1:n.terms]))

w2.top.d2 <- t(w2.top.d2)
kable(w2.top.d2, 
      caption = "Top 5 and bottom 5 of Dimension2 (LSA on TF-IDF)") %>%
   kable_paper()

```
<br>
For this LSA, dimension 2 is associated positively with "forest", "carbon", "climate", "emission" ,"energy", and negatively associated with "human", "computer", "machine", "ai", "robot".

```{r, echo=TRUE, warning=FALSE}
w2.top.d3 <- t(w2.top.d3)
kable(w2.top.d3, 
      caption = "Top 5 and bottom 5 of Dimension3 (LSA on TF-IDF)") %>%
   kable_paper()

```
<br>
Dimension 3 is associated positively with "regret", "sex", "woman", "love" ,"man", and negatively associated with "datum", "machine", "rule", "ai", "robot".

```{r, echo=TRUE, warning=FALSE}

w2.top.d4 <- t(w2.top.d4)
kable(w2.top.d4, 
      caption = "Top 5 and bottom 5 of Dimension4 (LSA on TF-IDF)") %>%
   kable_paper()

```
<br>
Dimension 4 is associated positively with "robot", "rule", "bee", "seaweed" ,"coral", and negatively associated with "machine", "human", "company", "datum", "ai".

Afterwards, we would like to see the relation between this LSA result and category of text. Therefore, we combine the LSA result with the category of text and represent every text on these two following plots. 
```{r, echo=TRUE, warning=FALSE,fig.height = 4}
TED.lsa2.source <- TED_full %>% 
  select(2) %>% cbind(as.data.frame(TED.lsa2$docs))

LSA_p3 <- ggplot(data=TED.lsa2.source,mapping = aes(
  x=V2,
  y=V3,
  color=cate))+
  geom_point()+
  labs(x = "dimension2",
       y = "dimension3",
       title = "Distribution of texts in different categories",
       subtitle = "LSA(TF-IDF) dimension 2 and 3")+
  scale_colour_discrete(
    name="Category",
    breaks=c("1","2","3"),
    labels=c("AI","Climate change","Relationships"))+
  theme(plot.title = element_text(size = 12))

LSA_p4 <- ggplot(data=TED.lsa2.source,mapping = aes(
  x=V3,
  y=V4,
  color=cate))+
  geom_point()+
  labs(x = "dimension3",
       y = "dimension4",
       title = "Distribution of texts in different categories",
       subtitle = "LSA(TF-IDF) dimension 3 and 4")+
  scale_colour_discrete(
    name="Category",
    breaks=c("1","2","3"),
    labels=c("AI","Climate change","Relationships"))+
  theme(plot.title = element_text(size = 12))

(LSA_p3+LSA_p4)+
  plot_layout(guides = "collect") & theme(legend.position = 'bottom')
```

From the left hand side plot:x-axis represents dimension 2 and y-axis represents dimension3. According to this plot, the "Climate change" category is positively associated with dimension2 while, the "Relationships" category is positively associated with dimension3. Moreover, the "AI" category is negatively associated with dimension2 and dimension3.

From the right hand side plot:x-axis represents dimension 3 and y-axis represents dimension4. According to this plot, It appears that a significant portion of the texts in the "AI" category are associated with dimension 4, although there is some variability in the direction of this association. It is not immediately clear from this plot alone what may be driving this pattern

## 6.2 LDA
We now turn to Latent Dirichlet Association (LDA). LDA is a Bayesian model for topic modeling: generative model. It is also to discover topics in a collection of documents. For the illustration, we will perform 4 topics again.
```{r, echo=TRUE, warning=FALSE}
TED.LDA <- LDA(
  convert(TED.dfm, to = "topicmodels"),
  k = 4,
  control = list(seed = 123))
```

First, we examine the top 5 words in each dimension. For example, the top 5 terms for topic 1 are "climate", "year", "make", "change" and "energy". 
```{r, echo=TRUE, warning=FALSE}
top5lda <- as.data.frame(topicmodels::terms(TED.LDA, 5))

head(top5lda) %>% flextable() %>% add_header_lines("Top5 terms for each topic") %>% autofit()

```
<br>
In addition, we can observe that Dimension1 has the highest topic strength.
```{r, echo=TRUE, warning=FALSE}

colnames(Topic_Strength2) <- c("Dimension", "Topic strength")

head(Topic_Strength2) %>% flextable() %>% add_header_lines("Topic strength by dimension") %>% autofit()

```

<br>
Then, we create a table to show the number of documents in each dimension. For example, topic 3 has the highest number of documents (439 documents). 
```{r, echo=TRUE, warning=FALSE}
ldatable <- as.data.frame(topicmodels::topics(TED.LDA) %>% table())
colnames(ldatable) <- c("Topic", "Number of documents")

head(ldatable) %>% flextable() %>% add_header_lines("Top5 terms for each topic") %>% autofit()

```
<br>
Subsequently, we applied the topic_diagnostics function to diagnose the *prominence*, *coherence* and *exclusivity* of each dimension.
```{r, echo=TRUE, warning=FALSE}
td <- topic_diagnostics(
  topic_model = TED.LDA, 
  dtm_data = convert(TED.dfm, to = "topicmodels"))

kable(td,
      caption = "Topic diagnostics")%>%
   kable_paper() %>%
   kableExtra::scroll_box(width = "100%", height = "200px")

```
<br>
Based on the analysis conducted, it appears that Topic 3 has the highest prominence among the identified topics. Additionally, the coherence of Topic 4 is found to be the highest, while the coherence of Topic 1 is the lowest. In terms of exclusivity, it is observed that Topic 1 has the highest exclusivity, while Topic 4 has the lowest exclusivity. These findings suggest that the characteristics of the identified topics vary in terms of their prominence, coherence, and exclusivity. 


```{r, echo=TRUE, warning=FALSE}
beta.long <- tidy(
  TED.LDA,
  matrix = "beta") # equivalent to melt (with this package)

beta.long %>% 
  group_by(topic) %>% 
  top_n(15, beta) %>% 
  ggplot(aes(reorder_within(term, beta, topic), beta)) + 
  geom_col(show.legend = FALSE) +
  ggtitle("Topic-term probabilities (Phi's)") +
  coord_flip()+
  facet_wrap(~ topic, scales = "free_y") +
  scale_x_reordered() + 
  xlab("Term") +
  theme(
    axis.text.y = element_text(size = 8),
    axis.text.x = element_text(size = 8),
    strip.text = element_text(size = 8))
```
Topic1 focus on "climate", "change", "energy", "water". 
Topic2 focus on "people", "ai", "work", "technology". 
Topic3 focus on "love", "life", "woman", "relationship". 
Topic4 focus on "robot", "thing", "brain", "human". 

```{r, echo=TRUE, warning=FALSE,fig.height = 4}

document <- rownames(TED.lsa.source)
TED.lsa.source <- cbind(document,TED.lsa.source)

gamma.long <- tidy(TED.LDA,matrix = "gamma") %>% 
  right_join(TED.lsa.source[1:2],by = "document")

gamma.long$cate<-factor(gamma.long$cate,
                       levels = c('1','2','3'),
                       labels = c("AI","Climate change","Relationships"))

gamma.long %>% ggplot(mapping = aes(x=document,y=gamma,fill=cate))+
  ggtitle("Topic-Document probabilities (Thetaâs)") +
  geom_col()+
  coord_flip() + 
  facet_wrap(~topic,ncol = 4)
  
  
```

The charts above show that the *Climate change* related documents mainly talk about Topic 1 while, the *Relationships* related documents mainly talk about Topic3. In addition, the *AI* related documents mainly talk about Topic 2 and Topic4. 

