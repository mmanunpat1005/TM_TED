---
title: "web"
author: "Jiaming"
date: "2022-11-17"
output: html_document
---

```{r,include=FALSE}
source(here::here("scripts/setup.R"))
```

```{r bbc web}
rD <- rsDriver(browser="chrome", port=4447L, verbose=F)
remDr <- rD$client
url <- "https://www.ted.com/"
remDr$navigate(url)
remDr$maxWindowSize()
html_page <- remDr$getPageSource()[[1]]
```

```{r}
# go to TED talk
drop_down <- remDr$findElement(using = 'xpath', '//*[@id="menu-button--0"]/div')
remDr$mouseMoveToLocation(webElement=drop_down)
remDr$findElement(using = 'xpath', '//*[@id="option-0--0"]/div[1]')$clickElement()
Sys.sleep(2)

# select lanuage to english
drop_down <- remDr$findElement(using = 'xpath', '//*[@id="languages"]')
remDr$mouseMoveToLocation(webElement=drop_down)
remDr$click(2)
remDr$findElement(using = "xpath", '//*[@id="languages"]/optgroup/option[1]')$clickElement()
Sys.sleep(1)

# select topic 
drop_down <- remDr$findElement(using = 'xpath', '//*[@id="topics"]')
remDr$mouseMoveToLocation(webElement=drop_down)
remDr$click(2)
remDr$findElement(using = "xpath", '//*[@id="topics"]/option[3]')$clickElement()
remDr$findElement(using = "xpath", '/html/body/div[4]/div[2]/div/div/div/div[3]/ul[1]/li[3]/a')$clickElement()
# if you want to change the capital of title, change the number in: [?]/a of the xpath
topic <- remDr$findElement(using = "partial link text", 'Climate change')  ## put topic name here
remDr$mouseMoveToLocation(webElement=topic)
remDr$click(2)
Sys.sleep(1)

# select duration as 6-12 mins
# drop_down <- remDr$findElement(using = 'xpath', '//*[@id="filters"]/div[1]/div/div[2]/div[1]/div[1]/div/div[2]/div/div[3]/select')
# remDr$mouseMoveToLocation(webElement=drop_down)
# remDr$click(2)
# remDr$findElement(using = "xpath", '//*[@id="filters"]/div[1]/div/div[2]/div[1]/div[1]/div/div[2]/div/div[3]/select/option[3]')$clickElement()
# Sys.sleep(1)

# select sort by the most relevant
drop_down <- remDr$findElement(using = 'xpath', '//*[@id="filters-sort"]')
remDr$mouseMoveToLocation(webElement=drop_down)
remDr$click(2)
remDr$findElement(using = "xpath", '//*[@id="filters-sort"]/optgroup/option[2]')$clickElement()

#capture all article titles
#since there are no independent list of all video that we wanteed to analyze before in the youtube channel, so i first crawl the title of each video over BBC website, then search on youtube
title <- read_html(html_page) %>% 
  html_nodes(".widget-progress-enabled a") %>% 
  html_text() %>%
  as.data.frame() %>%
  filter(. != "")
names(title) <- "title_name"
Sys.sleep(2)

```



```{r}
# when the function interrupted, start this to scrape the left videos. 
# waitforscrape <- title_all %>% filter(!title %in% TED$title)
```


```{r}
# first crawl all videos' titles on the first page
html_page <- remDr$getPageSource()[[1]]
page <- 3
title <- as.character()
speaker <- as.character()
views_times <- as.character()
page_num <- as.character()

for (i in 1:3) {
  
  page_title <- read_html(html_page) %>% 
    html_nodes(xpath = "//*[@id='browse-results']/div[1]/div/div/div/div/div[2]/h4[2]/a") %>% 
    html_text() 
  page_title <- gsub("\n","", page_title)
  #there are 36 videos in one page
  
  page_speaker <- read_html(html_page) %>% 
    html_nodes(xpath = "//*[@id='browse-results']/div[1]/div/div/div/div/div[2]/h4[1]") %>% 
    html_text() 
  
  page_views_times <- read_html(html_page) %>% 
    html_nodes(xpath = "//*[@id='browse-results']/div[1]/div/div/div/div/div[2]/div/span/span") %>% 
    html_text() 
  page_views_times <- gsub("\n","", page_views_times)
  
  page_page <- rep(i, times=length(page_title))
  
  next_page <- remDr$findElement(using = 'link text', 'Next')
  remDr$mouseMoveToLocation(webElement=next_page)
  remDr$click(2)
  Sys.sleep(5)
  
  Sys.sleep(5)
  
  html_page <- remDr$getPageSource()[[1]]
  
  title <- append(title, page_title)
  speaker <- append(speaker, page_speaker)
  views_times <- append(views_times, page_views_times)
  page_num <- append(page_num, page_page)

}

browse_result <- data.frame()
browse_result <- data.frame(
  "page" = page_num,
  "title" = title,
  "speaker" = speaker,
  "views_times" = views_times,
  "cate" = "Climate Change"
)
# first_page <- remDr$findElement(using = 'xpath', '//*[@id="browse-results"]/div[2]/div/a[2]')
#   remDr$mouseMoveToLocation(webElement=first_page)
#   remDr$click(2)
#   Sys.sleep(3)
# html_page <- remDr$getPageSource()[[1]]
```

```{r}
# save title name list temporary, ideally export to save
title_all <- browse_result
#fwrite(title_all, file = here::here("data/title_all.csv"))
```


```{r}
#click in each video to capture infos
introduction <- as.character()
likes <- as.character()
tanscript <- as.character()
title_re <- as.character()
n <- length(waitforscrape$title)

  for (i in 1:n) {
    
    Sys.sleep(3)
    
    search <- remDr$findElement(using = 'xpath', '//*[@id="filters"]/div[1]/div/div[2]/div[1]/div[1]/div/div[1]/div/input')
    search$clickElement()
    Sys.sleep(5)
     
    search$clearElement()
    search$sendKeysToElement(list(waitforscrape$title[i], key = "enter"))
    Sys.sleep(8)
    
    # click in the video
    video_page <- remDr$findElement(using = 'xpath', "//*[@id='browse-results']/div[1]/div[1]/div/div/div/div[2]/h4[2]/a")
    remDr$mouseMoveToLocation(webElement=video_page)
    remDr$click(2)
    Sys.sleep(15)
    
    video_title <- waitforscrape$title[i]
    
    # open transcript
    drop_down <- remDr$findElement(using = 'xpath', "//*[@id='maincontent']/div/div/div/div/div[2]/div[3]/div[2]/button")
    remDr$mouseMoveToLocation(webElement=drop_down)
    remDr$click(2)
    Sys.sleep(5)
    
    # begin to crawl infos
    html_page <- remDr$getPageSource()[[1]]
    
    video_sum <- read_html(html_page) %>% 
      html_nodes(xpath = "//*[@id='maincontent']/div/div/div/div/div[2]/div[3]/div[1]/div[2]/div/div") %>% 
      html_text() 
    video_sum <- video_sum[1]
    Sys.sleep(5)
    
    video_likes <- read_html(html_page) %>% 
      html_nodes(xpath = "//*[@id='maincontent']/div/div/div/div/div[2]/div[1]/div[3]/button[1]/div/div/span") %>% html_text() 
    Sys.sleep(5)
    
    video_tanscript <- read_html(html_page) %>% 
      html_nodes(xpath = "//*[@id='maincontent']/div/div/div/aside/div[2]/div[2]/div/div/div[1]") %>%
      html_text() 
    Sys.sleep(5)
    
    remDr$goBack()
    Sys.sleep(5)
    
    introduction <- append(introduction, video_sum)
    likes <- append(likes,video_likes)
    tanscript <- append(tanscript, video_tanscript)
    title_re <- append(title_re, video_title)
  
  }
video_info <- data.frame(
  
  "title" = title_re,
  "introduction" = introduction,
  "likes" = likes,
  "tanscript" = tanscript
)
```

```{r}
# save what have done temporary
TED_2 <- video_info
```

```{r}
# merge with the title name list
TED <- left_join(title_all, TED_2, by="title")
```

```{r}
fwrite(TED, file = here::here("data/TED.csv"))
```

```{r, include=FALSE}
remDr$closeServer()
remDr$close()
rm(remDr)
rm(rD)
gc()
```